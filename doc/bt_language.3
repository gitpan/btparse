.rn '' }`
''' $RCSfile$$Revision$$Date$
'''
''' $Log$
'''
.de Sh
.br
.if t .Sp
.ne 5
.PP
\fB\\$1\fR
.PP
..
.de Sp
.if t .sp .5v
.if n .sp
..
.de Ip
.br
.ie \\n(.$>=3 .ne \\$3
.el .ne 3
.IP "\\$1" \\$2
..
.de Vb
.ft CW
.nf
.ne \\$1
..
.de Ve
.ft R

.fi
..
'''
'''
'''     Set up \*(-- to give an unbreakable dash;
'''     string Tr holds user defined translation string.
'''     Bell System Logo is used as a dummy character.
'''
.tr \(*W-|\(bv\*(Tr
.ie n \{\
.ds -- \(*W-
.ds PI pi
.if (\n(.H=4u)&(1m=24u) .ds -- \(*W\h'-12u'\(*W\h'-12u'-\" diablo 10 pitch
.if (\n(.H=4u)&(1m=20u) .ds -- \(*W\h'-12u'\(*W\h'-8u'-\" diablo 12 pitch
.ds L" ""
.ds R" ""
'''   \*(M", \*(S", \*(N" and \*(T" are the equivalent of
'''   \*(L" and \*(R", except that they are used on ".xx" lines,
'''   such as .IP and .SH, which do another additional levels of
'''   double-quote interpretation
.ds M" """
.ds S" """
.ds N" """""
.ds T" """""
.ds L' '
.ds R' '
.ds M' '
.ds S' '
.ds N' '
.ds T' '
'br\}
.el\{\
.ds -- \(em\|
.tr \*(Tr
.ds L" ``
.ds R" ''
.ds M" ``
.ds S" ''
.ds N" ``
.ds T" ''
.ds L' `
.ds R' '
.ds M' `
.ds S' '
.ds N' `
.ds T' '
.ds PI \(*p
'br\}
.\"	If the F register is turned on, we'll generate
.\"	index entries out stderr for the following things:
.\"		TH	Title 
.\"		SH	Header
.\"		Sh	Subsection 
.\"		Ip	Item
.\"		X<>	Xref  (embedded
.\"	Of course, you have to process the output yourself
.\"	in some meaninful fashion.
.if \nF \{
.de IX
.tm Index:\\$1\t\\n%\t"\\$2"
..
.nr % 0
.rr F
.\}
.TH bt_language 3 "btparse, version 0.2" "8 September, 1997" "btparse"
.IX Title "bt_language 3"
.UC
.IX Name "bt_language - the BibTeX data language, as recognized by B<btparse>"
.if n .hy 0
.if n .na
.ds C+ C\v'-.1v'\h'-1p'\s-2+\h'-1p'+\s0\v'.1v'\h'-1p'
.de CQ          \" put $1 in typewriter font
.ft CW
'if n "\c
'if t \\&\\$1\c
'if n \\&\\$1\c
'if n \&"
\\&\\$2 \\$3 \\$4 \\$5 \\$6 \\$7
'.ft R
..
.\" @(#)ms.acc 1.5 88/02/08 SMI; from UCB 4.2
.	\" AM - accent mark definitions
.bd B 3
.	\" fudge factors for nroff and troff
.if n \{\
.	ds #H 0
.	ds #V .8m
.	ds #F .3m
.	ds #[ \f1
.	ds #] \fP
.\}
.if t \{\
.	ds #H ((1u-(\\\\n(.fu%2u))*.13m)
.	ds #V .6m
.	ds #F 0
.	ds #[ \&
.	ds #] \&
.\}
.	\" simple accents for nroff and troff
.if n \{\
.	ds ' \&
.	ds ` \&
.	ds ^ \&
.	ds , \&
.	ds ~ ~
.	ds ? ?
.	ds ! !
.	ds /
.	ds q
.\}
.if t \{\
.	ds ' \\k:\h'-(\\n(.wu*8/10-\*(#H)'\'\h"|\\n:u"
.	ds ` \\k:\h'-(\\n(.wu*8/10-\*(#H)'\`\h'|\\n:u'
.	ds ^ \\k:\h'-(\\n(.wu*10/11-\*(#H)'^\h'|\\n:u'
.	ds , \\k:\h'-(\\n(.wu*8/10)',\h'|\\n:u'
.	ds ~ \\k:\h'-(\\n(.wu-\*(#H-.1m)'~\h'|\\n:u'
.	ds ? \s-2c\h'-\w'c'u*7/10'\u\h'\*(#H'\zi\d\s+2\h'\w'c'u*8/10'
.	ds ! \s-2\(or\s+2\h'-\w'\(or'u'\v'-.8m'.\v'.8m'
.	ds / \\k:\h'-(\\n(.wu*8/10-\*(#H)'\z\(sl\h'|\\n:u'
.	ds q o\h'-\w'o'u*8/10'\s-4\v'.4m'\z\(*i\v'-.4m'\s+4\h'\w'o'u*8/10'
.\}
.	\" troff and (daisy-wheel) nroff accents
.ds : \\k:\h'-(\\n(.wu*8/10-\*(#H+.1m+\*(#F)'\v'-\*(#V'\z.\h'.2m+\*(#F'.\h'|\\n:u'\v'\*(#V'
.ds 8 \h'\*(#H'\(*b\h'-\*(#H'
.ds v \\k:\h'-(\\n(.wu*9/10-\*(#H)'\v'-\*(#V'\*(#[\s-4v\s0\v'\*(#V'\h'|\\n:u'\*(#]
.ds _ \\k:\h'-(\\n(.wu*9/10-\*(#H+(\*(#F*2/3))'\v'-.4m'\z\(hy\v'.4m'\h'|\\n:u'
.ds . \\k:\h'-(\\n(.wu*8/10)'\v'\*(#V*4/10'\z.\v'-\*(#V*4/10'\h'|\\n:u'
.ds 3 \*(#[\v'.2m'\s-2\&3\s0\v'-.2m'\*(#]
.ds o \\k:\h'-(\\n(.wu+\w'\(de'u-\*(#H)/2u'\v'-.3n'\*(#[\z\(de\v'.3n'\h'|\\n:u'\*(#]
.ds d- \h'\*(#H'\(pd\h'-\w'~'u'\v'-.25m'\f2\(hy\fP\v'.25m'\h'-\*(#H'
.ds D- D\\k:\h'-\w'D'u'\v'-.11m'\z\(hy\v'.11m'\h'|\\n:u'
.ds th \*(#[\v'.3m'\s+1I\s-1\v'-.3m'\h'-(\w'I'u*2/3)'\s-1o\s+1\*(#]
.ds Th \*(#[\s+2I\s-2\h'-\w'I'u*3/5'\v'-.3m'o\v'.3m'\*(#]
.ds ae a\h'-(\w'a'u*4/10)'e
.ds Ae A\h'-(\w'A'u*4/10)'E
.ds oe o\h'-(\w'o'u*4/10)'e
.ds Oe O\h'-(\w'O'u*4/10)'E
.	\" corrections for vroff
.if v .ds ~ \\k:\h'-(\\n(.wu*9/10-\*(#H)'\s-2\u~\d\s+2\h'|\\n:u'
.if v .ds ^ \\k:\h'-(\\n(.wu*10/11-\*(#H)'\v'-.4m'^\v'.4m'\h'|\\n:u'
.	\" for low resolution devices (crt and lpr)
.if \n(.H>23 .if \n(.V>19 \
\{\
.	ds : e
.	ds 8 ss
.	ds v \h'-1'\o'\(aa\(ga'
.	ds _ \h'-1'^
.	ds . \h'-1'.
.	ds 3 3
.	ds o a
.	ds d- d\h'-1'\(ga
.	ds D- D\h'-1'\(hy
.	ds th \o'bp'
.	ds Th \o'LP'
.	ds ae ae
.	ds Ae AE
.	ds oe oe
.	ds Oe OE
.\}
.rm #[ #] #H #V #F C
.SH "NAME"
.IX Header "NAME"
bt_language \- the BibTeX data language, as recognized by \fBbtparse\fR
.SH "INTRODUCTION"
.IX Header "INTRODUCTION"
One of the problems with BibTeX is that there is no formal specification
of the language.  This means that users exploring the arcane corners of
the language are largely on their own, and programmers implementing
their own parsers are completely on their own---except for observing the
behaviour of the original implementation.
.PP
Other parser implementors (Nelson Beebe of \fBbibclean\fR fame, in
particular) have taken the trouble to explain the language accepted by
their parser, and in that spirit the following is presented.
.PP
If you are unfamiliar with the arcana of regular and context-free
languages, you will not have any easy time understanding this.  This is
\fInot\fR an introduction to the BibTeX language; any LaTeX book would be
more suitable for learning the data language itself.
.SH "LEXICAL GRAMMAR"
.IX Header "LEXICAL GRAMMAR"
The lexical scanner has three distinct modes: top-level, in-entry, and
string.  Roughly speaking, top-level is the initial mode; we enter
in-entry mode on seeing an \f(CW@\fR at top-level; and on seeing the \f(CW}\fR or
\f(CW)\fR that ends the entry, we return to top-level.  We enter string mode
on seeing a \f(CW"\fR or non-entry-delimiting \f(CW{\fR from in-entry mode.  Note
that the lexical language is both non-regular (because braces must
balance) and context-sensitive (because \f(CW{\fR can mean different things
depending on its syntactic context).  That said, we will use regular
expressions to describe the lexical elements, because they are the
starting point used by the lexical scanner itself.  The rest of the
lexical grammar will be informally explained in the text.
.PP
From top-level, the following tokens are recognized according to the
regular expressions on the right:
.PP
.Vb 5
\&   at                    \e@
\&   newline               \en
\&   comment               \e%~[\en]*\en
\&   whitespace            [\e \er\et]+
\&   junk                  ~[\e@\en\e \er\et]+
.Ve
(Note that this is PCCTS regular expression syntax, which should be
fairly familar to users of other regex engines.  One oddity is that a
character class is negated as \f(CW~[...]\fR rather than \f(CW[^...]\fR.)
.PP
On seeing \f(CWat\fR at top-level, we enter in-entry mode.  Whitespace, junk,
newlines, and comments are all skipped, with the latter two incrementing
a line counter.  (Junk is explicitly recognized to allow for \f(CWbibtex\fR's
\*(L"implicit comment\*(R" scheme.)
.PP
From in-entry mode, we recognize newline, comment, and whitespace
identically to top-level mode.  In addition, the following tokens are
recognized:
.PP
.Vb 10
\&   name                  [a-z][a-z0-9:\e+/'\e.\e-_]*
\&   number                [0-9]+
\&   lbrace                \e{
\&   rbrace                \e}
\&   lparen                \e(
\&   rparen                \e)
\&   equals                =
\&   hash                  \e#
\&   comma                 ,
\&   quote                 \e"
.Ve
At this point, the lexical scanner starts to sound suspiciously like a
context-free grammar, rather than a collection of independent regular
expressions.  However, it is necessary to keep this complexity in the
scanner because certain characters (\f(CW{\fR and \f(CW(\fR in particular) have
very different lexical meanings depending on the tokens that have
preceded them in the input stream.
.PP
In particular, \f(CW{\fR and \f(CW(\fR are treated as \*(L"entry openers\*(R" if they
follow one \f(CWat\fR and one \f(CWname\fR token, unless the value of the \f(CWname\fR
token is \f(CW"comment"\fR.  (Note the switch from top-level to in-entry
between the two tokens.)  In the \f(CW@comment\fR case, the delimiter is
considered as starting a string, and we enter string mode.  Otherwise,
the delimiter is saved, and when we see a corresponding \f(CW}\fR or \f(CW)\fR it
is considered an \*(L"entry closer\*(R".  (Braces are balanced for free here
because the string lexer takes care of counting brace-depth.)
.PP
Anywhere else, \f(CW{\fR is considered as starting a string, and we enter
string mode.  \f(CW"\fR always starts a string, regardless of context.  The
other tokens (\f(CWname\fR, \f(CWnumber\fR, \f(CWequals\fR, \f(CWhash\fR, and \f(CWcomma\fR) are
recognized unconditionally.  Note that \f(CWname\fR here (used for entry
types, citation keys, field names, and macro names) is quite different
from the original BibTeX definition.  According to the BibTeX
documentation, a name is anything \fIexcept\fR a certain sequence of
characters; this means a field name of C<@!_\|_37} is perfectly legal with
BibTeX; in the name of decency, \fBbtparse\fR rejects such a monstrosity.
.PP
The string lexer recognizes \f(CWlbrace\fR, \f(CWrbrace\fR, \f(CWlparen\fR, and
\f(CWrparen\fR tokens in order to count brace- or parenthesis-depth.  This is
necessary so it knows when to accept a string delimited by braces or
parentheses.  (Note that a parenthesis-delimited string is only allowed
after \f(CW@comment\fR---this is not a normal BibTeX construct.)  In
addition, it converts each non-space whitespace character (newline,
carriage-return, and tab) to a single space.  (Sequences of whitespace
are not collapsed; that's the domain of string post-processing, which is
well removed from the scanner or parser.)  Finally, it accepts \f(CW"\fR to
delimit quote-delimited strings.  Apart from those restrictions, the
string lexer accepts anything up to the end-of-string delimiter.
.SH "SYNTACTIC GRAMMAR"
.IX Header "SYNTACTIC GRAMMAR"
(The language used to describe the grammar here is the extended
Backus-Naur Form (EBNF) used by PCCTS.  Terminals are represented by
uppercase strings, non-terminals by lowercase strings; terminal names
are mostly the same as those given in the lexical grammar above, apart
from the conversion to uppercase.  \f(CW( foo )*\fR means zero or more
repetitions of the \f(CWfoo\fR production, and \f(CW{ foo }\fR means an optional
\f(CWfoo\fR.)
.PP
A file is just a sequence of zero or more entries:
.PP
.Vb 1
\&   bibfile : ( entry )*
.Ve
An entry is an at-sign, a name (the \*(L"entry type"), and the entry body:
.PP
.Vb 1
\&   entry : AT NAME body
.Ve
A body is either a string (this alternative is only tried if the entry
type is \f(CW"comment"\fR) or the entry contents:
.PP
.Vb 2
\&   body : STRING
\&        | ENTRY_OPEN contents ENTRY_CLOSE
.Ve
(ENTRY_OPEN and ENTRY_CLOSE are either \f(CW{\fR and \f(CW}\fR or \f(CW(\fR and \f(CW)\fR,
depending what is seen in the input for a particular entry.)
.PP
There are three possible productions for the \*(L"contents\*(R" non-terminal.
Only one applies to any given entry, depending on the entry metatype
(which in turn depends on the entry type).  Currently, \fBbtparse\fR
supports four entry metatypes: comment, preamble, macro definition, and
regular.  The first two correspond to \f(CW@comment\fR and \f(CW@preamble\fR
entries; \*(L"macro definition\*(R" is for \f(CW@string\fR entries; and \*(L"regular\*(R" is
for all other entry types.  (The library will be extended to handle
\f(CW@modify\fR and \f(CW@alias\fR entry types, and corresponding \*(L"modify\*(R" and
\*(L"alias\*(R" metatypes, when BibTeX 1.0 is released and the exact syntax is
known.)  The \*(L"metatype\*(R" concept is necessary so that all entry types
that aren't specifically recognized fall into the \*(L"regular\*(R" metatype.
It's also convenient not to have to \f(CWstrcmp\fR the entry type all the
time.
.PP
.Vb 3
\&   contents : NAME COMMA fields     # for regular entries
\&            | fields                # for macro definition entries
\&            | value                 # for preamble entries
.Ve
\f(CWfields\fR is a comma-separated list of fields, with an optional single
trailing comma:
.PP
.Vb 2
\&   fields : field { COMMA fields }
\&          | 
.Ve
A \f(CWfield\fR is a single \*(L"field = value\*(R" assignment:
.PP
.Vb 1
\&   field : NAME EQUALS value
.Ve
A \f(CWvalue\fR is a series of simple values joined by \f(CW'#'\fR characters:
.PP
.Vb 1
\&   value : simple_value ( HASH simple_value )*
.Ve
A simple value is a string, number, or name (for macro invocations):
.PP
.Vb 3
\&   simple_value : STRING
\&                | NUMBER
\&                | NAME
.Ve

.rn }` ''
